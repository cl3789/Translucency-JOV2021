{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7SbsozZdNNJY"
   },
   "source": [
    "# Loading library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_2c7KTRWQw7X",
    "outputId": "57e40cb0-2aa0-48f1-c603-31cf95900f0f"
   },
   "outputs": [],
   "source": [
    "## Uncomment this to run image statistic \n",
    "#!pip uninstall scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yQVbA4PAQxZa",
    "outputId": "5153e9f7-2aa2-4a79-af71-c6564c6f6a57"
   },
   "outputs": [],
   "source": [
    "## Uncomment this to run image statistic \n",
    "#pip install scikit-image ## use scikit image 0.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OuTAH4yHMy7I",
    "outputId": "dc436702-836e-49b9-eaee-ba7afc031450"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA,KernelPCA\n",
    "\n",
    "from sklearn.manifold import TSNE,MDS\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import RepeatedKFold, StratifiedKFold, cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.metrics import pairwise_distances, cohen_kappa_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import mannwhitneyu,kruskal,wilcoxon, ttest_ind,spearmanr,kendalltau, entropy, pearsonr, skew, kurtosis, entropy\n",
    "from scipy.stats._stats import _kendall_dis\n",
    "from mlxtend.evaluate import permutation_test\n",
    "\n",
    "from skimage import io\n",
    "from skimage.color import rgb2lab, lab2lch, lab2rgb, lch2lab, rgb2xyz\n",
    "#from skimage.filters import difference_of_gaussians, gaussian\n",
    "from skimage.transform import resize\n",
    "#from skimage.filters.rank import entropy\n",
    "\n",
    "import cv2\n",
    "\n",
    "import os,glob\n",
    "from os import listdir,makedirs\n",
    "from os.path import isfile,join\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "from itertools import combinations \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "klL9jhaoNSMP"
   },
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UvLYj3CdNXgb"
   },
   "outputs": [],
   "source": [
    "# @title Loading data\n",
    "## Color EXP data\n",
    "drive_path = '/Users/chenxiliao/Dropbox/JOV 2021/exp data/'\n",
    "\n",
    "SAR_color_path = drive_path+'SAR Color 20.xlsx' ## SAR color exp\n",
    "BC_color_path = drive_path+'BC Color 20.xlsx' ## BC color exp\n",
    "naming_color_path = drive_path+'Naming Color 15.xlsx' ## MC color exp\n",
    "\n",
    "## Grayscale EXP data\n",
    "SAR_gray_path = drive_path+'SAR Gray 20.xlsx' ## SAR grayscale exp\n",
    "BC_gray_path = drive_path+'BC Gray 20.xlsx'  ## BC grayscale exp\n",
    "naming_gray_path = drive_path+'Naming Gray 15.xlsx' ## MC grayscale exp\n",
    "\n",
    "## Stimuli path (just the image names)\n",
    "color_stimiluli_path_sar = drive_path+'SAR_300.csv'\n",
    "color_stimiluli_path_bc = drive_path+'BC_300.csv'\n",
    "\n",
    "## Image stimuli path for image statistics extraction\n",
    "source_image = '/Users/chenxiliao/Dropbox/JOV 2021/300_ImgColor/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuC1WAvGN6g_"
   },
   "source": [
    "# Get stimuli label for each experiment. And show observer's name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wi8c8D8XOH6W",
    "outputId": "abe44370-d573-4ed5-942a-f25ef77fd576"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/chenxiliao/Dropbox/JOV 2021/exp data/SAR Trial List.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ea9d4c56d5f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmaterial_naming_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrive_path\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m'Material Categorization trials.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmaterial_naming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaterial_naming_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0msar_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrive_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'SAR Trial List.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"image_name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m## Preprocess material categorization results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/chenxiliao/Dropbox/JOV 2021/exp data/SAR Trial List.csv'"
     ]
    }
   ],
   "source": [
    "# @title Get label for each experiment\n",
    "## Get label for each experiment\n",
    "sar_label = pd.read_csv(color_stimiluli_path_sar, usecols= [\"image_name\"])\n",
    "BC_label = pd.read_csv(color_stimiluli_path_bc, usecols= [\"image_name\"])\n",
    "\n",
    "material_naming_path = drive_path+ 'Material Categorization trials.csv'\n",
    "material_naming = pd.read_csv(material_naming_path)\n",
    "sar_trial = pd.read_csv(drive_path+'SAR Trial List.csv', usecols= [\"image_name\"])\n",
    "\n",
    "## Preprocess material categorization results\n",
    "material_trials = pd.read_csv(material_naming_path)\n",
    "material_trials = material_trials.replace(['Food/cheese', 'Food/fruit/vegetables', 'Food/gummi/jelly', 'Food/meat/seafood', 'Food/candy/sugar',  'Food/shaved ice/ice cream/cream'],'Food in general', regex=True)\n",
    "material_trials = material_trials.replace(['Ivory', 'Marble/Stone/Concrete'], ['Marble/Stone/Concrete/Ivory','Marble/Stone/Concrete/Ivory'], regex=True)\n",
    "material_trials = material_trials.replace(['Plastic/Synthetic', 'Rubber'], ['Plastic/Synthetic/Rubber', 'Plastic/Synthetic/Rubber'], regex=True)\n",
    "\n",
    "## Get the name participants\n",
    "color_people_list = pd.ExcelFile(SAR_color_path).sheet_names\n",
    "gray_people_list = pd.ExcelFile(SAR_gray_path).sheet_names\n",
    "print(\"Color exp observers:\", len(color_people_list), color_people_list)\n",
    "print(\"Grayscale exp observers:\", len(gray_people_list), gray_people_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5S_M0qfPSHH"
   },
   "source": [
    "# SAR and BC data preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XDI_ZqIEbIyv"
   },
   "source": [
    "Important values:\n",
    "\n",
    "*   color_attribute_rank: Original trial order. contains the average rating, total votes, percent agreement, and rank of averge rating\n",
    "*   sorted_color_sar: sort color_attribute_rank from most translucent to most opaque\n",
    "*   sorted_gray_sar: sort images in grayscale exp in the same order as color condition \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_QtLwr6aRm_f"
   },
   "outputs": [],
   "source": [
    "# @title Helper functions: preprocess BC and SAR data\n",
    "def get_BC_data(BC_filepath):\n",
    "  '''Get the BC experiment classification results for each person'''\n",
    "  classification = pd.concat(pd.read_excel(BC_filepath, sheet_name=None, header = 0, usecols=\"A\"), ignore_index=True, axis=1)\n",
    "  obj_vote = pd.concat([BC_label,  classification], axis=1)\n",
    "  return classification\n",
    "\n",
    "def get_label_BC(data, num_people):\n",
    "  \"\"\"Get the Translucent, Opaque and Unsure classification label\n",
    "  using 60% as the threshold\"\"\"\n",
    "\n",
    "  threshold = 2\n",
    "\n",
    "  if data['total vote'] >= (num_people * 0.5+threshold) :\n",
    "      label = \"opaque\"\n",
    "  elif data['total vote'] <= (num_people * 0.5-threshold):\n",
    "      label = \"translucent\"\n",
    "  else:\n",
    "      label = \"unsure\"\n",
    "  return label\n",
    "\n",
    "def get_agreement(data, num_people):\n",
    "  \"\"\"Compute Percent Agreement for each image\"\"\"\n",
    "\n",
    "  if data['total vote'] > num_people/2:\n",
    "    # Percent Agreement for Opaque and Unsure images\n",
    "      agreement = data['total vote']/num_people\n",
    "  else:\n",
    "    # Percent Agreement for Translucent\n",
    "      agreement = (num_people - data['total vote'])/num_people\n",
    "  return agreement\n",
    "\n",
    "def sort_data(source_data):\n",
    "  \"\"\"Sort the data by ranking the Stimuli by Number of Votes.\n",
    "    Top Row: mostly voted as Translucent\n",
    "    Bottom Row: mostly voted as Opaque\"\"\"\n",
    "\n",
    "  sorted_data = source_data.sort_values(by='total vote', ascending = True)\n",
    "  return sorted_data\n",
    "\n",
    "def get_attribute_df(SAR_filepath, sar_label_path, BC_filepath, bc_label_path):\n",
    "  \"\"\"Get the Average SAR and Standard Deviation from all observers for each image. \"\"\"\n",
    "\n",
    "  sar_label = pd.read_csv(sar_label_path, usecols= [\"image_name\"])\n",
    "  BC_label = pd.read_csv(bc_label_path, usecols= [\"image_name\"])\n",
    "\n",
    "  ### Process SAR data ---------------\n",
    "  attributes_df = pd.DataFrame()\n",
    "  avg_attr = ['average_see_through', 'average_gloss', 'average_softness', 'average_glow', 'average_density']\n",
    "  for attr,column in zip(avg_attr,[\"C\", \"E\", \"G\", \"I\", \"K\"]) :\n",
    "    attribute = pd.concat(pd.read_excel(SAR_filepath, sheet_name=None,header = 0, usecols= column), ignore_index=True, axis=1)\n",
    "    attribute[attr] = attribute.mean(axis=1)\n",
    "    attributes_df = pd.concat([attributes_df,attribute[attr]], axis =1)\n",
    "  \n",
    "  attributes_df = pd.concat([sar_label,attributes_df], axis=1)\n",
    "  #print(attributes_df)\n",
    "\n",
    "  avg_attr_rank = ['see_through_avg_rank', 'gloss_avg_rank', 'softness_avg_rank', 'glow_avg_rank', 'density_avg_rank']\n",
    "  rank_method = 'min'\n",
    "  for rank, attr in zip(avg_attr_rank, avg_attr):\n",
    "    attributes_df[rank] = attributes_df[attr].rank(ascending= False, method=rank_method)\n",
    "\n",
    "  ### Process BC data ---------------\n",
    "  classification = pd.concat(pd.read_excel(BC_filepath, sheet_name=None, header = 0, usecols=\"A\"), ignore_index=True, axis=1)\n",
    "  classification['total vote'] = classification.sum(axis=1)\n",
    "  \n",
    "  # Get the number of observers\n",
    "  num_people = classification.shape[1]-1\n",
    "  print(\"Number of observers: \",num_people)\n",
    "\n",
    "  # give label to each image \n",
    "  classification['label'] = classification.apply(get_label_BC, num_people = num_people, axis=1)\n",
    "\n",
    "  # Calculate trial-by-trial degree of agreement \n",
    "  classification['agreement'] = classification.apply(get_agreement, num_people = num_people, axis=1)\n",
    "  obj_vote = pd.concat([BC_label, classification['total vote'], classification['label'],classification['agreement']], axis=1)\n",
    "\n",
    "  SAR_rank_labeled_df = pd.merge(attributes_df, obj_vote,  on='image_name')\n",
    "  SAR_rank_labeled_df = pd.merge(SAR_rank_labeled_df, sar_label, on='image_name')\n",
    "\n",
    "  return SAR_rank_labeled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JifVzjvfgLOM"
   },
   "outputs": [],
   "source": [
    "# @title Helper functions: BC and SAR data analysis and plots\n",
    "def get_BC_diff(threshold):\n",
    "\n",
    "  \"\"\"Get the images which have label flip.\n",
    "  threshold: threshold of the difference between the number of vote for being opaque between grayscale and color conditions.\n",
    "  \"\"\"\n",
    "\n",
    "  diff_BC = pd.DataFrame()\n",
    "  ## Subtract grayscale total vote for Opaque from color condition\n",
    "  diff_BC[\"Color-Gray\"] = color_attributes_rank[\"total vote\"] - gray_attribute_rank[\"total vote\"]\n",
    "  diff_BC = pd.concat([sar_label,  diff_BC[\"Color-Gray\"], color_attributes_rank[\"label\"], gray_attribute_rank[\"label\"]], axis=1)\n",
    "  diff_BC.columns.values[2] = \"color label\"\n",
    "  diff_BC.columns.values[3] = \"gray label\"\n",
    "\n",
    "  #diff_BC.plot.bar(x='image_name', y= 'Color-Gray',color = 'purple', figsize=(18,8), label='Color-Gray vote')\n",
    "  #plt.axhline(y=0, color='r', linestyle='dashdot', label = 'zero difference')\n",
    "\n",
    "  label_switched = diff_BC.loc[(diff_BC['color label'] != diff_BC['gray label']) & ((diff_BC['Color-Gray'] >= threshold) | (diff_BC['Color-Gray'] <= (-1 * threshold)))]\n",
    "  label_switched['condition'] = label_switched['color label'].str.cat(label_switched['gray label'], sep=' -> ')\n",
    "  label_switched = label_switched.sort_values(by='Color-Gray', ascending = True)\n",
    "\n",
    "  label_switched['condition'].hist(xrot=70,bins=12, grid=False)\n",
    "  plt.title('Stimuli labels are Flipped')\n",
    "  \n",
    "  return label_switched\n",
    "\n",
    "def plot_BC_rdm(color_BC, gray_BC,  metric = \"hamming\", lim = 1):\n",
    "  \"\"\"Plot the RDMs of BC with chosen distance metric.\n",
    "  And show the Manny U test P value to compare Translucent, Unsure and Opaque\n",
    "  regions in color and grayscale conditions\"\"\"\n",
    "\n",
    "  ## Reorder RDM. The same as Figure 3 (I)\n",
    "  new_index = sorted_color_sar['image_name'].tolist()\n",
    "\n",
    "  def preprocess_rdm(data):\n",
    "    bc_data = pd.concat([BC_label, data], axis=1)\n",
    "    bc_data.set_index('image_name', inplace=True)\n",
    "    bc_data_sorted = bc_data.reindex(new_index).to_numpy()\n",
    "    bc_data_sorted[bc_data_sorted == 0] = 2\n",
    "    return bc_data_sorted\n",
    "\n",
    "  color_BC = preprocess_rdm(color_BC)\n",
    "  gray_BC = preprocess_rdm(gray_BC)\n",
    "\n",
    "  ### Compute RDM using hamming distance\n",
    "  rdm_color = pairwise_distances(color_BC, metric=metric)\n",
    "  rdm_gray = pairwise_distances(gray_BC, metric=metric)\n",
    "\n",
    "  num_opaque, num_trans, num_unsure = sorted_color_sar.label.value_counts()[0], sorted_color_sar.label.value_counts()[1], sorted_color_sar.label.value_counts()[2]\n",
    "\n",
    "  def mannyU(rdm):\n",
    "    trans = rdm[0:num_trans, 0:num_trans]\n",
    "    trans = trans[np.triu_indices(trans.shape[0], k = 1)]\n",
    "\n",
    "    unsure = rdm[num_trans:(num_trans+num_unsure), num_trans:(num_trans+num_unsure)]\n",
    "    unsure = unsure[np.triu_indices(unsure.shape[0], k = 1)]\n",
    "    \n",
    "    opaque = rdm[num_trans+num_unsure:300, num_trans+num_unsure:300]\n",
    "    opaque = opaque[np.triu_indices(opaque.shape[0], k = 1)]\n",
    "\n",
    "    return trans,unsure,opaque\n",
    "  \n",
    "  trans_c, unsure_c, opaque_c =  mannyU(rdm_color)\n",
    "  trans_g, unsure_g, opaque_g =  mannyU(rdm_gray)\n",
    "\n",
    "\n",
    "  fig = plt.figure(figsize=(15, 15))\n",
    "  plt.subplot(121),plt.imshow(rdm_color, cmap = 'Oranges'), plt.colorbar(label='Dissimilarity value', shrink=0.5),plt.clim(0, lim)\n",
    "  plt.title('Color BC RDM'), plt.xticks([]), plt.yticks([])\n",
    "  plt.subplot(122),plt.imshow(rdm_gray, cmap = 'Oranges'),plt.colorbar(label='Dissimilarity value', shrink=0.5),  plt.clim(0, lim)\n",
    "  plt.title('Gray BC RDM'), plt.xticks([]), plt.yticks([])\n",
    "  plt.show()\n",
    "  \n",
    "  method = 'less'\n",
    "  U_tran,p_tran =  mannwhitneyu(trans_c,trans_g, alternative= method)\n",
    "  print(\"Wilcox P of Translucent region:\", p_tran, \"U:\", U_tran)\n",
    "  U_unsure,p_unsure =  mannwhitneyu(unsure_c,unsure_g, alternative= method)\n",
    "  print(\"Wilcox P of Unsure region:\", p_unsure, \"U:\", U_unsure)\n",
    "  U_op,p_op=  mannwhitneyu(opaque_c,opaque_g, alternative= method)\n",
    "  print(\"Wilcox P of Opaque region:\", p_op, \"U:\", U_op)\n",
    "\n",
    "\n",
    "def get_kappa_matrix(BC_data):\n",
    "  \"\"\"Generate kappa of pairs of individuals\"\"\"\n",
    "  np_people = BC_data.to_numpy().T\n",
    "  np_label_person = list(BC_data.columns)\n",
    "\n",
    "  num_people = len(np_label_person)\n",
    "\n",
    "  kappa_matrix = np.zeros((num_people,num_people))\n",
    "\n",
    "  perm = combinations(range(num_people),2)\n",
    "\n",
    "  for comb in list(perm): \n",
    "    kappa = cohen_kappa_score(np_people[comb[0]], np_people[comb[1]])\n",
    "    kappa_matrix[comb[0]][comb[1]] = kappa\n",
    "    kappa_matrix[comb[1]][comb[0]] = kappa\n",
    "\n",
    "  return kappa_matrix\n",
    "\n",
    "def plot_kappa_matrix(BC_data, condition, palatte):\n",
    "  \"\"\"Plot Cohen's Matrix.\n",
    "  condition: \"color\" or \"gray\" \"\"\"\n",
    "\n",
    "  p_matrix = get_kappa_matrix(BC_data)\n",
    "\n",
    "  p_matrix_inv = p_matrix.T\n",
    "  lower_mat = p_matrix_inv[np.triu_indices(p_matrix_inv.shape[0], k = 1)]\n",
    "  #print(\"count none or minimal or weak:\", np.sum(lower_mat < 0.6))\n",
    "\n",
    "  mask = np.zeros_like(p_matrix_inv, dtype=np.bool)\n",
    "  mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "  # Set up the figure\n",
    "  f, ax = plt.subplots(figsize=(11, 9))\n",
    "  \n",
    "  # Generate a custom diverging colormap\n",
    "  sns.set(font_scale = 2)\n",
    "  color_map = sns.mpl_palette(palatte, 4)\n",
    "\n",
    "  if condition == \"color\":\n",
    "    label_person = list(range(21))\n",
    "  else:\n",
    "    label_person = list(range(21,41))\n",
    "\n",
    "  sns_plot = sns.heatmap(p_matrix_inv, mask=mask, xticklabels=label_person, yticklabels=label_person, cmap=color_map, vmax=0.8, vmin=0,\n",
    "          square=True, linewidths=.5)\n",
    "  plt.xticks(rotation=90)\n",
    "\n",
    "\n",
    "def _set_index_mat(data):\n",
    "  \"\"\"Set the index to image_name\"\"\"\n",
    "  data = pd.concat([sar_label, data], axis=1)\n",
    "  data.set_index('image_name', inplace=True)\n",
    "  return data\n",
    "\n",
    "def get_each_attribute(SAR_filepath, order=\"reorder\"):\n",
    "  \"\"\"Get the Five attribute, return separate dataframes\n",
    "  \n",
    "    order: trial_num or reorder\n",
    "    trial_num: ordered by trial number in the experiment\n",
    "    reorder:  re-order each dataframe in the order from most opaque --> most translucent as in color condition\n",
    "     \"\"\"\n",
    "\n",
    "  ### Process SAR data ---------------\n",
    "  attr_rate = []\n",
    "  for attr in [\"C\", \"E\", \"G\", \"I\", \"K\"]:\n",
    "    rating =  _set_index_mat(pd.concat(pd.read_excel(SAR_filepath, sheet_name=None,header = 0, usecols= attr), ignore_index=True, axis=1))\n",
    "    attr_rate.append(rating)\n",
    "  \n",
    "  see_through, gloss, softness, glow, density = [attr_rate[i] for i in range(5)]\n",
    "  \n",
    "  if order == 'trial_num':\n",
    "    return see_through, gloss, softness, glow, density\n",
    "\n",
    "  elif order == 'reorder':\n",
    "    see_through_re, gloss_re, softness_re, glow_re, density_re = [attr_rate[i].reindex(sorted_color_sar.index) for i in range(5)]\n",
    "    return see_through_re, gloss_re, softness_re, glow_re, density_re\n",
    "\n",
    "\n",
    "def plot_attr_histogram(trial_index):\n",
    "  \"\"\"Plot the attribute histograms for a specific image for color and grayscale condition observers\n",
    "  trial_index: trial_index in SAR exp\n",
    "  \"\"\"\n",
    "\n",
    "  color_attr = [see_through_color, gloss_color, softness_color, glow_color, density_color]\n",
    "  gray_attr = [see_through_gray, gloss_gray, softness_gray, glow_gray, density_gray]\n",
    "  title_color = [\"See throughness\",  \"Glossiness\", \"Softness\", \"Glow\" , \"Density\" ]\n",
    "\n",
    "  fig = plt.figure(figsize=(35, 8))\n",
    "  plt.subplots_adjust(wspace = 0.3, hspace = 0.3)\n",
    "  plt.rcParams[\"axes.edgecolor\"] = \"black\"\n",
    "  plt.rcParams[\"axes.linewidth\"] = 1\n",
    "\n",
    "  rows = 2\n",
    "  columns = 5\n",
    "  xlabel = list(range(1,7))\n",
    "\n",
    "  ## Plot histogram in color condition\n",
    "  for i,(color,title) in enumerate(zip(color_attr,title_color)):\n",
    "    ax = fig.add_subplot(rows, columns, i+1)\n",
    "    color.T[trial_index].plot(kind='hist',bins=[1,2,3,4,5,6,7] ,rwidth=0.7,xticks=xlabel, ylim=(0,14),  xlim=(0,6.5), align='left',color = \"crimson\", grid = False)\n",
    "    plt.title(title + \"/Trial Index:\" + str(trial_index), fontsize= 12)\n",
    "    ax.set_facecolor(\"white\")\n",
    "    ax.axes.xaxis.set_visible(False)\n",
    "    ax.axes.yaxis.set_visible(False)\n",
    "    \n",
    "  ## Plot histogram in grayscale condition\n",
    "  for i,(gray,title) in enumerate(zip(gray_attr,title_color)):\n",
    "    ax = fig.add_subplot(rows, columns, i+6)\n",
    "    gray.T[trial_index].plot(kind='hist',bins=[1,2,3,4,5,6,7] ,rwidth=0.7, xticks=xlabel, ylim=(0,14),  xlim=(0,6.5), align='left', grid = False)\n",
    "    plt.title(\"Gray \" + title + \"/Trial Index:\" + str(trial_index), fontsize= 12)\n",
    "    ax.set_facecolor(\"white\")\n",
    "    ax.axes.xaxis.set_visible(False)\n",
    "    ax.axes.yaxis.set_visible(False)\n",
    "    \n",
    "  plt.show()\n",
    "\n",
    "\n",
    "def _get_attribute_prob_image(sar_data):\n",
    "  \"\"\"Compute the distribution of attribute ratings for each image\"\"\"\n",
    "\n",
    "  A = np.empty((0,6), int)\n",
    "  for image in range(sar_data.shape[0]):\n",
    "    list_rate = []\n",
    "    for i in range(1,7):\n",
    "      try:\n",
    "        list_rate.append(sar_data.iloc[image].value_counts(1)[i])\n",
    "      except KeyError:\n",
    "        list_rate.append(0)\n",
    "\n",
    "    if 0 in list_rate:\n",
    "      num_of_0 = list_rate.count(0)\n",
    "      list_rate = [0.0001 if x  == 0 else x - 0.0001 /((6/num_of_0)-1) for x in list_rate]\n",
    "    else:\n",
    "      list_rate = list_rate\n",
    "\n",
    "    arr = np.array(list_rate)\n",
    "    A = np.vstack([A, arr])\n",
    "  return A\n",
    "\n",
    "def _get_prob_dist_images():\n",
    "  \"\"\"Get the table of distribution of ratings for color and grayscale conditions\"\"\"\n",
    "\n",
    "  color_prob_image = []\n",
    "  gray_prob_image = []\n",
    "  for i in [see_through_color, gloss_color, softness_color, glow_color, density_color]:\n",
    "    color_prob_image.append(_get_attribute_prob_image(i))\n",
    "  for j in [see_through_gray, gloss_gray, softness_gray, glow_gray, density_gray]:\n",
    "    gray_prob_image.append(_get_attribute_prob_image(j))\n",
    "  return color_prob_image, gray_prob_image\n",
    "\n",
    "def compute_KL_images(mode, color_type):\n",
    "  \"\"\"Compute KL value for each image\"\"\"\n",
    "\n",
    "  see_through_KL_list = []\n",
    "  gloss_KL_list = []\n",
    "  softness_KL_list = []\n",
    "  glow_KL_list = []\n",
    "  density_KL_list = []\n",
    "  all_attribute = [see_through_KL_list, gloss_KL_list, softness_KL_list, glow_KL_list, density_KL_list ]\n",
    "  color_prob_image, gray_prob_image = _get_prob_dist_images()\n",
    "\n",
    "  for i in range(len(all_attribute)):\n",
    "    for image in range(0,300):\n",
    "      if mode == \"gray|color\" and color_type == None:\n",
    "        all_attribute[i].append(entropy(gray_prob_image[i][image], qk = color_prob_image[i][image]))\n",
    "      elif mode == \"color|gray\" and color_type == None:\n",
    "        all_attribute[i].append(entropy(color_prob_image[i][image], qk = gray_prob_image[i][image]))\n",
    "      elif mode == \"individual diff\":\n",
    "        if color_type == \"color\":\n",
    "          all_attribute[i].append(entropy(color_prob_image[i][image], qk = [1/6, 1/6, 1/6, 1/6, 1/6, 1/6]))\n",
    "        elif color_type == \"gray\":\n",
    "          all_attribute[i].append(entropy(gray_prob_image[i][image], qk = [1/6, 1/6, 1/6, 1/6, 1/6, 1/6]))\n",
    "\n",
    "  KL_df = pd.DataFrame()\n",
    "  KL_attr = ['see_through KL-value', 'gloss KL-value', 'softness KL-value', 'glow KL-value', 'density KL-value']\n",
    "  for attr_list, attr in zip(all_attribute,KL_attr):\n",
    "    attribute = pd.DataFrame(attr_list,columns=[attr])\n",
    "    KL_df = pd.concat([KL_df,attribute], axis =1)\n",
    "\n",
    "  KL_df = pd.concat([sar_label,KL_df], axis=1)\n",
    "  #print(attributes_df)\n",
    "  \n",
    "  #KL_value_df['total KL'] =  KL_value_df['see_through KL-value'] + KL_value_df['gloss KL-value'] + KL_value_df['softness KL-value'] + KL_value_df['glow KL-value'] + KL_value_df['density KL-value']\n",
    "\n",
    "  #KL_df = pd.concat([KL_df,  color_attributes_rank[\"label\"], gray_attribute_rank[\"label\"]], axis=1 )\n",
    " \n",
    "  return KL_df\n",
    "\n",
    "def plot_KL(KL_df, attribute):\n",
    "\n",
    "    bins =[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,6]\n",
    "\n",
    "    # make the histogram\n",
    "    data = KL_df[attribute]\n",
    "    hist, bin_edges = np.histogram(data,bins) \n",
    "\n",
    "    fig,ax = plt.subplots()\n",
    "\n",
    "    ax.bar(range(len(hist)),hist,width=1, \n",
    "          color = \"gold\", \n",
    "          )\n",
    "    ax.grid(False) \n",
    "    ax.set_facecolor(\"white\")\n",
    "    ax.set_xticklabels([])\n",
    "    plt.ylim(0,70)\n",
    "        \n",
    "\n",
    "def plt_kl_hist(KL_df):\n",
    "  \"\"\"Plot distribution of KL divergence of 300 images for each attribute\"\"\"\n",
    "\n",
    "  def plot_one_KL(attribute):\n",
    "    bins =[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,6]\n",
    "\n",
    "    # make the histogram\n",
    "    data = KL_df[attribute]\n",
    "    hist, bin_edges = np.histogram(data,bins) \n",
    "\n",
    "    #fig,ax = plt.subplots()\n",
    "\n",
    "    ax.bar(range(len(hist)),hist,width=1, \n",
    "          color = \"gold\", \n",
    "          )\n",
    "    ax.grid(False) \n",
    "    ax.set_facecolor(\"white\")\n",
    "    ax.set_xticklabels([])\n",
    "    plt.ylim(0,70)\n",
    "\n",
    "\n",
    "  KL_attr = ['see_through KL-value', 'gloss KL-value', 'softness KL-value', 'glow KL-value', 'density KL-value']\n",
    "  titles = [\"See throughness\",  \"Glossiness\", \"Softness\", \"Glow\" , \"Density\" ]\n",
    "  \n",
    "  fig = plt.figure(figsize=(35, 4))\n",
    "  plt.subplots_adjust(wspace = 0.3, hspace = 0.3)\n",
    "  plt.rcParams[\"axes.edgecolor\"] = \"black\"\n",
    "  plt.rcParams[\"axes.linewidth\"] = 1\n",
    "\n",
    "  for i,(attr,title) in enumerate(zip(KL_attr,titles)):\n",
    "    ax = fig.add_subplot(1, 5, i+1)\n",
    "    plot_one_KL(attr)\n",
    "    plt.title(title)\n",
    "    ax.set_facecolor(\"white\")\n",
    "    #ax.axes.xaxis.set_visible(False)\n",
    "    #ax.axes.yaxis.set_visible(False)\n",
    "\n",
    "def get_skew(SAR_filepath, sar_label_path, BC_filepath, bc_label_path):\n",
    "  \"\"\"Get the Average SAR score from all observers. \n",
    "     Also Rank the stimuli based on std attribute. High ranking --> Larger Std\n",
    "     \"\"\"\n",
    "  \n",
    "  ### Process BC data ---------------\n",
    "  classification = pd.concat(pd.read_excel(BC_filepath, sheet_name=None, header = 0, usecols=\"A\"), ignore_index=True, axis=1)\n",
    "  classification['total vote'] = classification.sum(axis=1)\n",
    "\n",
    "  num_people = classification.shape[1]-1\n",
    " \n",
    "  sar_label = pd.read_csv(sar_label_path, usecols= [\"image_name\"])\n",
    "  BC_label = pd.read_csv(bc_label_path, usecols= [\"image_name\"])\n",
    "\n",
    "  ## Create dummy raters\n",
    "  an_array = np.array([1,2,3,4,5,6])\n",
    "  repetitions = 300\n",
    "  repeats_array = np.tile(an_array, (repetitions, 1))\n",
    "  dummy_rater = pd.DataFrame(repeats_array)\n",
    "\n",
    "  ### Process SAR data ---------------\n",
    "  skew_df = pd.DataFrame()\n",
    "  skew_attr = ['skew_see_through', 'skew_gloss', 'skew_softness', 'skew_glow', 'skew_density']\n",
    "  for attr,column in zip(skew_attr,[\"C\", \"E\", \"G\", \"I\", \"K\"]) :\n",
    "    ratings = pd.concat(pd.read_excel(SAR_filepath, sheet_name=None,header = 0, usecols= column), ignore_index=True, axis=1)\n",
    "    ratings = pd.concat([ratings,  dummy_rater], axis=1)\n",
    "    skew_df[attr] = ratings.skew(axis=1)\n",
    "    #skew_df = pd.concat([skew_df,skew_df[attr]], axis =1)\n",
    "  \n",
    "  skew_df = pd.concat([sar_label,skew_df], axis=1)\n",
    "\n",
    "  classification['label'] = classification.apply(get_label_BC, num_people = num_people, axis=1)\n",
    "  classification['agreement'] = classification.apply(get_agreement, num_people = num_people, axis=1)\n",
    " \n",
    "  obj_vote = pd.concat([BC_label,  classification['total vote'], classification['label'],classification['agreement']], axis=1)\n",
    "\n",
    "  skew = pd.merge(skew_df, obj_vote, on='image_name')\n",
    "  skew = skew.reindex(sorted_color_sar.index)\n",
    "\n",
    "  return skew\n",
    "\n",
    "def plot_skew_shift(skew_color_sorted,skew_gray_sorted):\n",
    "  diff_skew = pd.DataFrame()\n",
    "  for column, attribute in zip(['Shift see through', 'Shift gloss', 'Shift softness', 'Shift glow', 'Shift density' ], \n",
    "                       ['skew_see_through', 'skew_gloss', 'skew_softness', 'skew_glow', 'skew_density' ]) :\n",
    " \n",
    "    print(column, attribute)\n",
    "    \n",
    "    ## Distance of skewness shift\n",
    "    diff_skew[column] = -(skew_gray_sorted[attribute] - skew_color_sorted[attribute])\n",
    "  \n",
    "    ax = diff_skew[column].plot.bar(figsize=(18,12), width=1, color = \"purple\")\n",
    "\n",
    "    plt.axhline(y=0, color='r', linestyle='dashdot', label = 'zero difference')\n",
    "    plt.title(column + \"/// Above(/Below) zero: tendency to move to HIGHER(/LOWER) rating in grayscale.\")\n",
    "\n",
    "    ax.set(xticklabels=[])\n",
    "    ax.set_ylim(-2, 2)\n",
    "    plt.show()\n",
    "  \n",
    "\n",
    "def get_SAR_BC_people(SAR_filepath, sar_label_path, BC_filepath, bc_label_path):\n",
    "  \"\"\"Get the SAR and BC data for each observer\"\"\"\n",
    "\n",
    "  SAR_color_people = pd.ExcelFile(SAR_filepath)\n",
    "  people_list = SAR_color_people.sheet_names\n",
    "  print(people_list)\n",
    "\n",
    "  sar_label = pd.read_csv(sar_label_path, usecols= [\"image_name\"])\n",
    "  BC_label = pd.read_csv(bc_label_path, usecols= [\"image_name\"])\n",
    "\n",
    "  data_color = [] ##  data_color is a list of df of different people\n",
    "\n",
    "  num_attribute = 5\n",
    "  data_color_person =  np.empty([0, num_attribute * 300])\n",
    "  for sheetname in people_list:\n",
    "    sar_color_person = pd.read_excel(SAR_filepath, sheet_name= str(sheetname), header = 0, usecols=\"C, E, G, I, K\")\n",
    "\n",
    "    sar_color_person = sar_color_person.rename(columns={\"SeeThroughness_score.response\": \"see_throughness\", \"Glossiness_score.response\": \"glossiness\", \"Hardness_score.response\": \"softness\", \"Glow_score.response\": \"glow\", \"Density_score.response\": \"density\"}) \n",
    "\n",
    "    sar_color_person = pd.concat([sar_label, sar_color_person], axis=1)\n",
    "\n",
    "    bc_color_person = pd.read_excel(BC_filepath, sheet_name= str(sheetname), header = 0, usecols=\"A\")\n",
    "    bc_color_person = bc_color_person.rename(columns={\"key_resp.keys\":\"label\"})\n",
    "    bc_color_person = pd.concat([BC_label, bc_color_person], axis=1)\n",
    "\n",
    "    person_rating_color = pd.merge(sar_color_person, bc_color_person, on='image_name')\n",
    "\n",
    "    data_color.append(person_rating_color)\n",
    "  \n",
    "  return data_color\n",
    "\n",
    "def get_LR_StratifiedKFold(features, data):\n",
    "  \"\"\"Logistic Regression model with Kfold CV\"\"\"\n",
    "\n",
    "  # Separating out the features\n",
    "  x = data.loc[:, features].values\n",
    "  y = data.loc[:,['label']].values\n",
    "\n",
    "  cv = StratifiedKFold(n_splits=3, random_state=1, shuffle=True)\n",
    "\n",
    "  model = LogisticRegression(penalty = 'l2', C= 0.9, random_state = 0)\n",
    "\n",
    "  scores = cross_val_score(model, x, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "  return np.mean(scores), np.std(scores)\n",
    "\n",
    "def plot_mean_acc(model, data, features, condition):\n",
    "  \"\"\"Plot Mean prediction accuracy for the each observer\"\"\"\n",
    "  \n",
    "  mean_list = np.array([])\n",
    "  std_list = np.array([])\n",
    "  for i in range(len(data)):\n",
    "    mean_acc, std_acc = model(features, data[i])\n",
    "    mean_list = np.append(mean_list,mean_acc )\n",
    "    std_list = np.append(std_list,std_acc )\n",
    "\n",
    "  if condition == \"color\":\n",
    "    labels = list(range(1,21))\n",
    "  else:\n",
    "    labels = list(range(21,41))\n",
    "  x_pos = np.arange(len(labels))\n",
    "\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.bar(x_pos, mean_list,\n",
    "        yerr= std_list,\n",
    "        align='center',\n",
    "        alpha=0.9,\n",
    "        ecolor='black',\n",
    "        capsize=5,\n",
    "        color=\"#66aed6\",\n",
    "        #color = '#e50405'\n",
    "        )\n",
    "  ax.set_ylabel(\"Averge Accuracy of 3-fold Cross Validation\")\n",
    "  ax.set_xticks(x_pos)\n",
    "  ax.set_xticklabels(labels)\n",
    "  ax.set_title(\"Model Mean accuracy on different observers \" + str(condition))\n",
    "  ax.yaxis.grid(True)\n",
    "\n",
    "  #plt.tight_layout()\n",
    "  plt.xticks(fontsize=14, rotation=90)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dmwIZo881Zp1"
   },
   "outputs": [],
   "source": [
    "# @title Helper functions: Material Categorization task\n",
    "def _get_mat_category(data, num_people):\n",
    "\n",
    "  \"\"\"Assign labels to images: Food vs. Non-food\"\"\"\n",
    "  if data['Food in general'] >= (num_people * 0.5 + 2) :\n",
    "      label = \"Food in general\"\n",
    "  elif data['Food in general'] <= (num_people * 0.5 - 2):\n",
    "      label = \"Non-food\"\n",
    "  else:\n",
    "      label = \"Unsure\"\n",
    "  return label\n",
    "\n",
    "def _get_correct_category(data):\n",
    "\n",
    "  \"\"\"Assign labels to images: Food vs. Non-food\"\"\"\n",
    "  if data['Category'] != data['Category Food'] :\n",
    "      label = \"Different\"\n",
    "  else:\n",
    "      label = \"Same as ground truth \"\n",
    "  return label\n",
    "\n",
    "def get_naming(naming_path, mode):\n",
    "  \"\"\"Get the naming result from all observers\n",
    "     \"\"\"\n",
    "  mat_index = material_naming[\"image_name\"]\n",
    "\n",
    "  category = pd.concat(pd.read_excel(naming_path, sheet_name=None,header = 0, usecols=\"H\"), ignore_index=True, axis=1)\n",
    "  category = category.replace(['{\"Q0\":\"', '\"}'],'', regex=True)\n",
    "  \n",
    "\n",
    "  # Re-organize the material categories\n",
    "  if mode == \"ten\":\n",
    "    category = category.replace(['Food/cheese', 'Food/fruit/vegetables', 'Food/gummi/jelly', 'Food/meat/seafood', 'Food/candy/sugar',  'Food/shaved ice/ice cream/cream'],'Food in general', regex=True)\n",
    "    category = category.replace(['Ivory', 'Marble/Stone/Concrete'], ['Marble/Stone/Concrete/Ivory','Marble/Stone/Concrete/Ivory'], regex=True)\n",
    "    category = category.replace(['Plastic/Synthetic', 'Rubber'], ['Plastic/Synthetic/Rubber', 'Plastic/Synthetic/Rubber'], regex=True)\n",
    "    \n",
    "    mat_list = ['Food in general', 'Crystal/quartz/mineral/jade', 'Glass', 'Marble/Stone/Concrete/Ivory', 'Plastic/Synthetic/Rubber', 'Soap', 'Wax', 'Wood', \n",
    "              'Chalk', 'Metal']\n",
    "  \n",
    "  elif mode == \"food\":\n",
    "    category = category.replace(['Food/cheese', 'Food/fruit/vegetables', 'Food/gummi/jelly', 'Food/meat/seafood', 'Food/candy/sugar',  'Food/shaved ice/ice cream/cream'],'Food in general', regex=True)\n",
    "    category = category.replace(['Crystal/quartz/mineral/jade','Glass','Ivory', 'Marble/Stone/Concrete','Plastic/Synthetic', 'Rubber','Soap', 'Wax', 'Wood', \n",
    "              'Chalk', 'Metal' ], 'Non-food', regex=True)\n",
    "    mat_list = ['Food in general', 'Non-food']\n",
    "\n",
    "  binary_result = pd.concat([mat_index,category], axis = 1)\n",
    "  binary_result.set_index('image_name', inplace=True)\n",
    "\n",
    "  A = np.empty((0,len(mat_list)), int) ## save the counts in array\n",
    "  for i in range(category.shape[0]):\n",
    "    mat_count = []\n",
    "    for mat in (mat_list):\n",
    "      try:\n",
    "          mat_count.append(category.iloc[i].value_counts(0)[mat])\n",
    "      except KeyError:\n",
    "          mat_count.append(0)\n",
    "    arr = np.array(mat_count)\n",
    "    A = np.vstack([A, arr])\n",
    "\n",
    "  num_people = category.shape[1]\n",
    "  print(\"Number of observers:\", num_people)\n",
    "  \n",
    "  mat_count = pd.DataFrame(A, columns = mat_list)\n",
    "  mat_count[\"max\"] = mat_count.max(axis = 1)\n",
    "\n",
    "  # Sort the image \n",
    "  mat_count = pd.concat([mat_index,mat_count], axis = 1)\n",
    "  sorted_data = mat_count.sort_values(by=['Food in general'], ascending = False)\n",
    "  sorted_data = sorted_data.drop(columns=['max'])\n",
    "  sorted_data['Category'] = sorted_data.apply(_get_mat_category, num_people = num_people, axis=1)\n",
    "  sorted_data.set_index('image_name', inplace=True)\n",
    "\n",
    "  true_category = pd.read_csv(material_naming_path, usecols=['image_name', 'Category Food'])\n",
    "  true_category.set_index('image_name', inplace=True)\n",
    "\n",
    "  sorted_data = pd.merge(sorted_data, true_category, left_index=True, right_index=True)\n",
    "  sorted_data['Compare'] = sorted_data.apply(_get_correct_category, axis=1)\n",
    "  #print(sorted_data)\n",
    "\n",
    "  #mat_count.plot(kind='bar', stacked=True,  figsize=(18,8))\n",
    "\n",
    "  return binary_result, sorted_data\n",
    "\n",
    "\n",
    "def plot_naming_img_rdm(color_naming, gray_naming,  metric = \"hamming\", lim = 1):\n",
    "  \"\"\"Plot RDM of binary classification of Food vs.Non-Food\"\"\"\n",
    "\n",
    "  color_naming = color_naming.replace(['Food in general','Non-food'],[1,0], regex=True)\n",
    "  gray_naming = gray_naming.replace(['Food in general','Non-food'],[1,0], regex=True)\n",
    "  \n",
    "  ordered_matrix = mat_result_color.sort_values(by=['Food in general'], ascending = False)\n",
    "  color_sorted = color_naming.reindex(ordered_matrix.index).to_numpy()\n",
    "  gray_sorted = gray_naming.reindex(ordered_matrix.index).to_numpy()\n",
    "\n",
    "  rdm_color = pairwise_distances(color_sorted, metric=metric)\n",
    "  rdm_gray = pairwise_distances(gray_sorted, metric=metric)\n",
    "\n",
    "\n",
    "  fig = plt.figure(figsize=(15, 15))\n",
    "  plt.subplot(121),plt.imshow(rdm_color, cmap = 'Oranges'), plt.colorbar(label='Dissimilarity value', shrink=0.5),plt.clim(0, lim)\n",
    "  plt.title('Color BC RDM'), plt.xticks([]), plt.yticks([])\n",
    "  plt.subplot(122),plt.imshow(rdm_gray, cmap = 'Oranges'),plt.colorbar(label='Dissimilarity value', shrink=0.5),  plt.clim(0, lim)\n",
    "  plt.title('Gray BC RDM'), plt.xticks([]), plt.yticks([])\n",
    "  plt.show()\n",
    "\n",
    "  rp = rdm_correlation_kendall_a(rdm_color, rdm_gray)\n",
    "  print(\"Kendall Tau a between Color and Grayscale RDM: \", rp[0])\n",
    "  print(\"Kendall P-value: \", rp[1])\n",
    "\n",
    "\n",
    "def get_SAR_BC_naming(mode, SAR_filepath, sar_label_path, BC_filepath, bc_label_path, naming_filepath, naming_label_path):\n",
    "\n",
    "  SAR_color_people = pd.ExcelFile(SAR_filepath)\n",
    "  SAR_people_list = SAR_color_people.sheet_names\n",
    "\n",
    "  sar_label = pd.read_csv(sar_label_path, usecols= [\"image_name\"])\n",
    "  BC_label = pd.read_csv(bc_label_path, usecols= [\"image_name\"])\n",
    "\n",
    "  naming_people_list = pd.ExcelFile(naming_filepath).sheet_names\n",
    "  naming_label = pd.read_csv(naming_label_path)\n",
    "  data_color = [] ##  data_color is a list of df of different people\n",
    "\n",
    "  common_people =[value for value in SAR_people_list if value in naming_people_list]\n",
    "  num_attribute = 5\n",
    "  data_color_person =  np.empty([0, num_attribute * 300])\n",
    "  print(common_people)\n",
    "  for sheetname in common_people:\n",
    "    sar_color_person = pd.read_excel(SAR_filepath, sheet_name= str(sheetname), header = 0, usecols=\"C, E, G, I, K\")\n",
    "    np_person_color = sar_color_person.to_numpy().reshape((1,num_attribute * 300))\n",
    "    data_color_person = np.append(data_color_person, np_person_color, axis=0)\n",
    "\n",
    "    sar_color_person = sar_color_person.rename(columns={\"SeeThroughness_score.response\": \"see_throughness\", \"Glossiness_score.response\": \"glossiness\", \"Hardness_score.response\": \"softness\", \"Glow_score.response\": \"glow\", \"Density_score.response\": \"density\"}) \n",
    "    sar_color_person = pd.concat([sar_label, sar_color_person], axis=1)\n",
    "\n",
    "    bc_color_person = pd.read_excel(BC_filepath, sheet_name= str(sheetname), header = 0, usecols=\"A\")\n",
    "    bc_color_person = bc_color_person.rename(columns={\"key_resp.keys\":\"label\"})\n",
    "    bc_color_person = pd.concat([BC_label, bc_color_person], axis=1)\n",
    "\n",
    "    naming_color_person = pd.read_excel(naming_filepath, sheet_name= str(sheetname), header = 0, usecols=\"H\")\n",
    "    naming_color_person = pd.concat([naming_label,naming_color_person], axis = 1)\n",
    "    naming_color_person = naming_color_person.replace(['{\"Q0\":\"', '\"}'],'', regex=True)\n",
    "\n",
    "    if mode == \"ten\":\n",
    "      naming_color_person = naming_color_person.replace(['Food/cheese', 'Food/fruit/vegetables', 'Food/gummi/jelly', 'Food/meat/seafood', 'Food/candy/sugar',  'Food/shaved ice/ice cream/cream'],'Food in general', regex=True)\n",
    "      naming_color_person = naming_color_person.replace(['Ivory', 'Marble/Stone/Concrete'], ['Marble/Stone/Concrete/Ivory','Marble/Stone/Concrete/Ivory'], regex=True)\n",
    "      naming_color_person = naming_color_person.replace(['Plastic/Synthetic', 'Rubber'], ['Plastic/Synthetic/Rubber', 'Plastic/Synthetic/Rubber'], regex=True)\n",
    "\n",
    "    elif mode == \"food\":\n",
    "      naming_color_person = naming_color_person.replace(['Food/cheese', 'Food/fruit/vegetables', 'Food/gummi/jelly', 'Food/meat/seafood', 'Food/candy/sugar',  'Food/shaved ice/ice cream/cream'],'Food in general', regex=True)\n",
    "      naming_color_person = naming_color_person.replace(['Crystal/quartz/mineral/jade','Glass','Ivory', 'Marble/Stone/Concrete','Plastic/Synthetic', 'Rubber','Soap', 'Wax', 'Wood', \n",
    "            'Chalk', 'Metal' ], 'Non-food', regex=True)\n",
    " \n",
    "    \n",
    "    sar_color_person.set_index('image_name', inplace=True)\n",
    "    naming_color_person.set_index('image_name', inplace=True)\n",
    "    \n",
    "    #person_rating_color = pd.merge(naming_color_person, sar_color_person, left_index=True, right_index=True)\n",
    "    person_rating_color = naming_color_person.merge(sar_color_person, left_index=True, right_index=True)\n",
    "    person_rating_color = person_rating_color.reset_index()\n",
    "    #print(person_rating_color)\n",
    "\n",
    "    data_color.append(person_rating_color)\n",
    "    \n",
    "  return data_color\n",
    "\n",
    "def plot_naming_people_rdm(data_color,data_gray, metric = 'hamming',  lim = 1):\n",
    "  #print(data_color)\n",
    "  data_color = data_color.replace(['Food in general', 'Crystal/quartz/mineral/jade', 'Glass', 'Marble/Stone/Concrete/Ivory', 'Plastic/Synthetic/Rubber', 'Soap', 'Wax', 'Wood', \n",
    "              'Chalk', 'Metal'],range(10), regex=True).to_numpy()\n",
    "  distance_color= pairwise_distances(data_color.T, metric=metric) \n",
    "\n",
    "  data_gray = data_gray.replace(['Food in general', 'Crystal/quartz/mineral/jade', 'Glass', 'Marble/Stone/Concrete/Ivory', 'Plastic/Synthetic/Rubber', 'Soap', 'Wax', 'Wood', \n",
    "              'Chalk', 'Metal'],range(10), regex=True).to_numpy()\n",
    "  distance_gray= pairwise_distances(data_gray.T, metric=metric) \n",
    "\n",
    "  fig = plt.figure(figsize=(15, 15))\n",
    "  plt.subplot(121),plt.imshow(distance_color, cmap = 'Oranges'), plt.colorbar(label='Dissimilarity value', shrink=0.5),plt.clim(0, lim)\n",
    "  plt.title('Color MC RDM'), plt.xticks([]), plt.yticks([])\n",
    "  plt.subplot(122),plt.imshow(distance_gray, cmap = 'Oranges'),plt.colorbar(label='Dissimilarity value', shrink=0.5),  plt.clim(0, lim)\n",
    "  plt.title('Gray MC RDM'), plt.xticks([]), plt.yticks([])\n",
    "  plt.show()\n",
    "\n",
    "  rdm_count_color = distance_color[np.triu_indices(distance_color.shape[0], k = 1)]\n",
    "  rdm_count_gray = distance_gray[np.triu_indices(distance_gray.shape[0], k = 1)]\n",
    "\n",
    "  bins = np.linspace(0.2, 0.5, 20)\n",
    "  plt.hist(rdm_count_color, bins, alpha=0.6,label='color',color=\"firebrick\", rwidth=0.8)\n",
    "  plt.hist(rdm_count_gray, bins, alpha=0.25,label='grayscale', color=\"midnightblue\", rwidth=0.8)\n",
    "  plt.legend(loc='upper right')\n",
    "  plt.show()\n",
    "\n",
    "  U, p = mannwhitneyu(rdm_count_color, rdm_count_gray)\n",
    "  print(\"Mann Whitney U P value:\", p, \"U:\", U)\n",
    "\n",
    "\n",
    "def plot_TSNE(data, features, label, targets, colors, perplexity_level):\n",
    "  \"\"\"tSNE plot using SAR ratings as features\"\"\"\n",
    " \n",
    "  x = data.loc[:, features].values\n",
    "\n",
    "  # Separating out the target\n",
    "  y = data.loc[:,[label]].values\n",
    "\n",
    "  tsne = TSNE(n_components=2, verbose=1, perplexity=perplexity_level, n_iter=350, random_state=1)\n",
    "  tsne_results = tsne.fit_transform(x)\n",
    "  tsne_Df = pd.DataFrame(data = tsne_results\n",
    "                , columns = ['tSNE 1', 'tSNE 2'])\n",
    "\n",
    "  final_tsneDf = pd.concat([ data['image_name'], tsne_Df,  data[label]], axis = 1)\n",
    "\n",
    "\n",
    "  fig = plt.figure(figsize = (12,12))\n",
    "  ax = fig.add_subplot(1,1,1, facecolor='white') \n",
    "  #ax.set_xlabel('tSNE 1', fontsize = 15)\n",
    "  #ax.set_ylabel('tSNE 2', fontsize = 15)\n",
    "  #ax.set_title('2 component tSNE', fontsize = 20)\n",
    "  for target, color in zip(targets,colors):\n",
    "      indicesToKeep = final_tsneDf[label] == target\n",
    "      ax.scatter(final_tsneDf.loc[indicesToKeep, 'tSNE 1']\n",
    "                , final_tsneDf.loc[indicesToKeep, 'tSNE 2']\n",
    "                , c = color\n",
    "                , s = 100)\n",
    "  \n",
    "  #for i, txt in enumerate(final_tsneDf['image_name']):\n",
    "  #  ax.annotate(txt, (final_tsneDf['tSNE 1'][i], final_tsneDf['tSNE 2'][i]), fontsize=10)\n",
    "    #print(txt)\n",
    "      \n",
    "  legend = ax.legend(targets)\n",
    "  legend.remove()\n",
    "  ax.set(xticklabels=[])\n",
    "  ax.set(yticklabels=[])\n",
    "  ax.set_xlim(-30, 30)\n",
    "  plt.grid(\"off\")\n",
    "  ax.grid()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QPyjLOl0axL3",
    "outputId": "0a655140-6c4c-4bc4-b31e-54b1113ab92d"
   },
   "outputs": [],
   "source": [
    "# @title Get BC and SAR results for both color and grayscale conditions\n",
    "## BC and SAR results of color exp\n",
    "color_BC = get_BC_data(BC_color_path)\n",
    "color_attributes_rank  = get_attribute_df(SAR_color_path, color_stimiluli_path_sar, BC_color_path, color_stimiluli_path_bc)\n",
    "sorted_color_sar = sort_data(color_attributes_rank)\n",
    "print(\"Got color_BC and sorted_color_sar.\"  )\n",
    "## BC result of grayscale exp\n",
    "gray_BC = get_BC_data(BC_gray_path)\n",
    "gray_attribute_rank = get_attribute_df(SAR_gray_path, color_stimiluli_path_sar, BC_gray_path, color_stimiluli_path_bc)\n",
    "sorted_gray_sar = gray_attribute_rank.reindex(sorted_color_sar.index)\n",
    "print(\"Got gray_BC and sorted_gray_sar.\"  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save BC and SAR data for PCA plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_attributes_rank  = get_attribute_df(SAR_color_path, color_stimiluli_path_sar, BC_color_path, color_stimiluli_path_bc)\n",
    "#color_attributes_rank.to_csv('/Users/chenxiliao/Dropbox/JOV 2021/exp data/color_BC_SAR/color_labeled.csv')\n",
    "\n",
    "gray_attribute_rank = get_attribute_df(SAR_gray_path, color_stimiluli_path_sar, BC_gray_path, color_stimiluli_path_bc)\n",
    "#gray_attribute_rank.to_csv('/Users/chenxiliao/Dropbox/JOV 2021/exp data/gray_BC_SAR/gray_labeled.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "WzIoF-zuH7IS"
   },
   "outputs": [],
   "source": [
    "# @title Define feature for plots\n",
    "# Set features for PCA and TSNE plot\n",
    "features_sar = ['see_throughness', \n",
    "             'glossiness', \n",
    "             'softness',\n",
    "             'glow',\n",
    "             'density'\n",
    "              ]\n",
    "\n",
    "# 1 for opaque, 0 for translucent\n",
    "colors_BC = ['c', 'm']\n",
    "targets_BC = [1,0] \n",
    "\n",
    "features_avg = ['average_see_through', \n",
    "             'average_gloss', \n",
    "              'average_softness',\n",
    "              'average_glow', \n",
    "              'average_density']\n",
    "\n",
    "targets_avg = ['translucent', 'unsure', 'opaque']\n",
    "colors_3 = ['r', 'g', 'b']\n",
    "\n",
    "## tSNE categories\n",
    "targets_material_8 = ['Food in general', 'Metal', 'Crystal/quartz/mineral/jade','Marble/Stone/Concrete/Ivory',\n",
    "                    'Glass', 'Plastic/Synthetic/Rubber', \n",
    "                    'Soap', 'Wax' ]\n",
    "                  \n",
    "\n",
    "colors_material_8 = ['orange', 'black','gray', 'silver',\n",
    "                   'pink', 'magenta', \n",
    "                   'turquoise', 'royalblue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "0oU3tLscQckI"
   },
   "outputs": [],
   "source": [
    "# @title Image statistics\n",
    "def split3(img):\n",
    "    \"\"\"Splits a 3-channel image into its constituent channels.\n",
    "    Convenience function using numpy slices, ~300x faster than cv2.split().\"\"\"\n",
    "    assert(isinstance(img, np.ndarray))\n",
    "    assert(nchannels(img) == 3)\n",
    "    return img[:, :, 0], img[:, :, 1], img[:, :, 2]\n",
    "\n",
    "def nchannels(img):\n",
    "    \"\"\"Returns the number of channels in an image.\"\"\"\n",
    "    assert(isinstance(img, np.ndarray))\n",
    "    if img.ndim < 3:\n",
    "        return 1\n",
    "    else:\n",
    "        return img.shape[2]\n",
    "\n",
    "\n",
    "def get_Chroma_stat(img):\n",
    "  \"\"\"Calculate image statistics for each image\"\"\"\n",
    "\n",
    "  #img_lab = rgb2lab(img)\n",
    "  img_luv = cv2.cvtColor(img,cv2.COLOR_RGB2Luv)\n",
    "  img_luv = img_luv.astype(np.float32)\n",
    "  img_luv[:,:,0] = (100*img_luv[:,:,0])/255.\n",
    "  img_luv[:,:,1] = ((354*img_luv[:,:,1])/255.)-134\n",
    "  img_luv[:,:,2] = ((262*img_luv[:,:,2])/255.)-140\n",
    "  img_lch = lab2lch(img_luv)\n",
    "  l,c,h = split3(img_lch)\n",
    "\n",
    "  ## Mask out the black background\n",
    "  threshold = 7 #lower value near the black background tends to be affected by digit noise. \n",
    "  saturation = copy.deepcopy(c)\n",
    "  #print(np.where(l>threshold))\n",
    "  saturation[np.where(l>threshold)] = saturation[np.where(l>threshold)]/l[np.where(l>threshold)]\n",
    "  \n",
    "  #saturation[np.where(saturation>1)] = 1\n",
    "  img_xyz = rgb2xyz(img)\n",
    "  x,lum,z = split3(img_xyz)\n",
    "\n",
    "  ### Mask out the black background\n",
    "  mask_L = np.ma.masked_where(l <= threshold, l).mask\n",
    "  L_img = np.ma.array(l, mask=mask_L)\n",
    "  L_img = L_img[~L_img.mask]\n",
    "  Lum_img = np.ma.array(lum, mask=mask_L)\n",
    "  Lum_img = Lum_img[~Lum_img.mask]\n",
    "  #C_img = np.ma.array(c, mask=mask_L)\n",
    "  C_img = np.ma.array(saturation, mask=mask_L)\n",
    "  C_img = C_img[~C_img.mask]\n",
    "\n",
    "  #corr1, p1 = pearsonr(C_img, Lum_img)\n",
    "\n",
    "  mean_L = np.mean(Lum_img, dtype=np.float64)\n",
    "  mean_C = np.mean(C_img, dtype=np.float64)\n",
    "  \n",
    "  std_L = np.std(Lum_img, dtype=np.float64)\n",
    "  std_C = np.std(C_img, dtype=np.float64)\n",
    "\n",
    "  skew_L = skew(Lum_img,axis=None)\n",
    "  skew_C = skew(C_img,axis=None)\n",
    "\n",
    "  ## Chroma and Lightness Correlation\n",
    "  try:\n",
    "    corr_CL,_ = pearsonr(C_img, Lum_img)\n",
    "  except ValueError:\n",
    "    corr_CL = 0\n",
    "  \n",
    "  stats = [std_C, skew_C, std_L, skew_L, corr_CL]\n",
    "  print(stats)\n",
    "  return stats\n",
    "\n",
    "def get_subbands_stats(img):\n",
    "  \"\"\"Get 3 subband images using difference of gaussian, and calculate image statistics\n",
    "  for each subband. Concatenate result in a list. \"\"\"\n",
    "  stats_all = []\n",
    "  original = get_Chroma_stat(img)\n",
    "  stats_all = stats_all + original\n",
    "\n",
    "  for i in [1,5]:\n",
    "    filter_img = difference_of_gaussians(img, i,30)\n",
    "    filter_img = filter_img.astype(\"float32\")\n",
    "    stat_band = get_Chroma_stat(filter_img)\n",
    "    stats_all = stats_all + stat_band\n",
    "  return stats_all\n",
    "\n",
    "def imag_stat(rating_data):\n",
    "  \"\"\"Extract the image statistics\"\"\"\n",
    "  color_stim = source_image # Source Folder\n",
    "\n",
    "  # Folder won't used\n",
    "  files = list(filter(lambda f: isfile(join(color_stim,f)), listdir(color_stim)))\n",
    "\n",
    "  # Create column names for the features\n",
    "  column_values = []\n",
    "  #features = ['std_C', 'skew_C', 'kur_C','rms_C', 'entropy_C', 'std_L', 'skew_L', 'kur_L', 'rms_L', 'entropy_L', 'corr_CL']\n",
    "  features = ['std_C', 'skew_C',  'std_L', 'skew_L','corr_CL']\n",
    "  for i in ['original_', 'sub1_', 'sub2_']:\n",
    "  #for i in ['sub1_', 'sub2_','sub3_']:\n",
    "    for j in features:\n",
    "      column_values.append(i + j)\n",
    "  #column_values = ['image_name'] + column_values + ['colorfulness']\n",
    "  column_values = ['image_name'] + column_values\n",
    "\n",
    "  image_stats = np.empty((0,len(column_values)), int) \n",
    "  print(\"Extracting features ---->\")\n",
    "  for image in files:\n",
    "    #print(image)\n",
    "    img_nam = [image[:-4]]\n",
    "    print(img_nam)\n",
    "    img = io.imread(os.path.join(color_stim,image))\n",
    "    #img = cv2.imread(os.path.join(color_stim,image))\n",
    "    #img = resize(img, (500,500),\n",
    "    #                   anti_aliasing=True)\n",
    "    #img = img.astype('float32')\n",
    "    #colorfulness = image_colorfulness(img)\n",
    "    stds = get_subbands_stats(img)\n",
    "    #img_features = img_nam + stds + colorfulness\n",
    "    img_features = img_nam + stds\n",
    "    arr = np.array(img_features)\n",
    "    image_stats = np.vstack([image_stats, arr])\n",
    "    \n",
    "\n",
    "  \n",
    "  stats = pd.DataFrame(data = image_stats, \n",
    "                  columns = column_values)\n",
    "  stats[column_values[1:]] = stats[column_values[1:]].apply(pd.to_numeric)\n",
    "  \n",
    "  rating_stat = pd.merge(rating_data, stats,  on='image_name')\n",
    "  print(\"Finished ---->\")\n",
    "  return rating_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4Nu6UK7e3It"
   },
   "source": [
    "# Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 531
    },
    "id": "jCfU40AwfV30",
    "outputId": "cb67dfdd-ea39-4559-c8d4-eb144f607018"
   },
   "outputs": [],
   "source": [
    "# @title (I) Plot BC exp. percent agreement for color and grayscale conditions\n",
    "agreement_color_line = sorted_color_sar.plot.line(x='image_name', y= 'agreement', figsize=(18,8), label='Color', color = 'r')\n",
    "sorted_gray_sar.plot.line(ax=agreement_color_line,x='image_name', y= 'agreement', linestyle='dashed', label='Grayscale')\n",
    "plt.title(\"Trial-by-trial agreement for BC experiment: Color\")\n",
    "plt.ylabel(\"Percentage Agreement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "id": "FTlo6MhHgp9F",
    "outputId": "3387ad1d-7b3b-4f2e-d389-9f79063139bf"
   },
   "outputs": [],
   "source": [
    "# @title (II) Classification label flips\n",
    "diff_label_BC = get_BC_diff(1)\n",
    "print(diff_label_BC.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show examples of 'opaque -> translucent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "Gt6eSxfxpXE-",
    "outputId": "e89d6a94-ef0a-4fab-a398-3fcdd64cd3d0"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "#diff_label_BC\n",
    "diff_label_BC.loc[diff_label_BC['condition'] == \"opaque -> translucent\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show examples of 'translucent -> opaque'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "nE1lGtwTIoAe",
    "outputId": "b3b3de47-d89b-44d8-f9e8-a112028fa8a1"
   },
   "outputs": [],
   "source": [
    "diff_label_BC.loc[diff_label_BC['condition'] == \"translucent -> opaque\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYNp25tmaNJ4"
   },
   "source": [
    "# Figure 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "EzM4TIjErtVv",
    "outputId": "b6ac6136-2f49-49e2-bfb9-0db6be023de9"
   },
   "outputs": [],
   "source": [
    "# @title (I) BC RDMs\n",
    "plot_BC_rdm(color_BC, gray_BC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oZXDitd7aQHX",
    "outputId": "ee503ec6-2e87-416e-8ce7-0ef9cdf0a6aa"
   },
   "outputs": [],
   "source": [
    "# @title (II) Cohen's Kappa Heatmap\n",
    "## Color condition\n",
    "plot_kappa_matrix(color_BC, \"color\", \"seismic\")\n",
    "\n",
    "## Grayscale condition\n",
    "plot_kappa_matrix(gray_BC, \"gray\", \"seismic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XlMWJzTtutMv"
   },
   "source": [
    "# Figure 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HdHZVJwSzurP"
   },
   "outputs": [],
   "source": [
    "# @title Get SAR data from observers used for histogram\n",
    "see_through_color, gloss_color, softness_color, glow_color, density_color = get_each_attribute(SAR_color_path, order = \"trial_num\")\n",
    "see_through_gray, gloss_gray, softness_gray, glow_gray, density_gray = get_each_attribute(SAR_gray_path, order = \"trial_num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "id": "5PxI_FDEzyfN",
    "outputId": "8f2db92c-c4f7-4f4b-d8f8-e3e4f5a68696"
   },
   "outputs": [],
   "source": [
    "# @title (I) Plot histograms for example images\n",
    "plot_attr_histogram('grapefruit5')\n",
    "plot_attr_histogram('glycerin4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155
    },
    "id": "9-vKWu0I7Kt5",
    "outputId": "6036ad55-00af-4d23-8b30-9ba55d124c78"
   },
   "outputs": [],
   "source": [
    "# @title (II) Plot distribution of KL divergence of 300 images\n",
    "KL_value_image = compute_KL_images(mode='gray|color', color_type = None)\n",
    "plt_kl_hist(KL_value_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KL_value_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KL_value_image[KL_value_image['see_through KL-value'] >= 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KL_value_image[KL_value_image['gloss KL-value'] >= 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KL_value_image[KL_value_image['softness KL-value'] >= 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KL_value_image[KL_value_image['glow KL-value'] >= 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KL_value_image[KL_value_image['density KL-value'] >= 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wxvVoJVfCS3y"
   },
   "outputs": [],
   "source": [
    "# @title (III) Plot skewness\n",
    "skew_adj_color = get_skew(SAR_color_path, color_stimiluli_path_sar, BC_color_path, color_stimiluli_path_bc)\n",
    "skew_adj_gray = get_skew(SAR_gray_path, color_stimiluli_path_sar, BC_gray_path, color_stimiluli_path_bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3m6sfLfwFvMj"
   },
   "source": [
    "*   Above centerline: Grayscale condition has higher ratings\n",
    "*   Below centerline: Color condition has higher ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "dkwVn9v7Cm6B",
    "outputId": "c156eb6f-e17a-4773-8aec-229081e1e97d"
   },
   "outputs": [],
   "source": [
    "plot_skew_shift(skew_adj_color,skew_adj_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JmmISKDEGams"
   },
   "source": [
    "# Figure 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "efftf-NNG57E",
    "outputId": "64166687-6ef4-4336-c4c1-3c37f9f6cc2e"
   },
   "outputs": [],
   "source": [
    "color_people_data  = get_SAR_BC_people(SAR_color_path, color_stimiluli_path_sar, BC_color_path, color_stimiluli_path_bc)\n",
    "gray_people_data  = get_SAR_BC_people(SAR_gray_path, color_stimiluli_path_sar, BC_gray_path, color_stimiluli_path_bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save observers data as csv files for Logistic Regression analysis in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to a csv file. This data is provided in the 'exp data' folder \n",
    "#for i in range(20):\n",
    "#    color_people_data[i].to_csv('/Users/chenxiliao/Dropbox/JOV 2021/exp data/color_BC_SAR/Color Person' + str(i+1) +'.csv')\n",
    "#    gray_people_data[i].to_csv('/Users/chenxiliao/Dropbox/JOV 2021/exp data/gray_BC_SAR/Gray Person' + str(i+1) +'.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7uWj2n8V3Z3M"
   },
   "source": [
    "# Figure 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDIZDWjb3u6H"
   },
   "source": [
    "Color Condition barchart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "id": "C9wpT98I3f2c",
    "outputId": "794cc76f-37c7-4134-9942-db864f4cd445"
   },
   "outputs": [],
   "source": [
    "binary_naming_color, mat_result_color = get_naming(naming_color_path, mode='food')\n",
    "ten_naming_color, ten_mat_color = get_naming(naming_color_path, mode='ten')\n",
    "mat_result_color.plot(kind='bar', stacked=True, color=[\"orange\",\"green\"],  figsize=(50,10) , ylim=(0,15), legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xcxJ9Jm31Q3"
   },
   "source": [
    "Grayscale Condition barchart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "id": "qE0FwHHa34mn",
    "outputId": "bd9f8b36-ffa4-401f-b1ad-6539186331a3"
   },
   "outputs": [],
   "source": [
    "binary_naming_gray, mat_result_gray = get_naming(naming_gray_path, 'food')\n",
    "ten_naming_gray, ten_mat_gray = get_naming(naming_gray_path, 'ten')\n",
    "mat_result_gray = mat_result_gray.reindex(mat_result_color.index)\n",
    "\n",
    "mat_result_gray.plot(kind='bar', stacked=True, color=[\"orange\",\"green\"], figsize=(50,10) , ylim=(0,15), legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eN6Z1oJN6m3R"
   },
   "source": [
    "# Figure 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 975
    },
    "id": "bn44uGhj6jAX",
    "outputId": "8abe1c8f-cee0-41d0-ebad-2bf9f8460a25"
   },
   "outputs": [],
   "source": [
    "# @title (II) Distribution of dissimilarity values\n",
    "plot_naming_people_rdm(ten_naming_color, ten_naming_gray, lim = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzZRtyGPAfqr"
   },
   "source": [
    "# Figure 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VeR_O2EFAjRp",
    "outputId": "6816e916-364a-4e9b-ec75-2869403f1d0c"
   },
   "outputs": [],
   "source": [
    "color_people_10cat = get_SAR_BC_naming('ten', SAR_color_path, color_stimiluli_path_sar, BC_color_path, color_stimiluli_path_bc, naming_color_path, material_naming_path )\n",
    "gray_people_10cat = get_SAR_BC_naming('ten', SAR_gray_path, color_stimiluli_path_sar, BC_gray_path, color_stimiluli_path_bc, naming_gray_path, material_naming_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NhAdz0lPH0xo"
   },
   "source": [
    "t-SNE plot for Color condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jKZxNA4ZGKYG",
    "outputId": "03bfca16-843a-4022-ca44-cf28ef319a1b"
   },
   "outputs": [],
   "source": [
    "for i in range(len(color_people_10cat)):\n",
    "  plot_TSNE(color_people_10cat[i], features_sar,'responses', targets_material_8, colors_material_8, perplexity_level = 15)\n",
    "  print(\"TSNE plot for color observer with 8 categories\", i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EflYYza6Hrhz"
   },
   "source": [
    "t-SNE plot for Grayscale condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "awsPht6UHyFV",
    "outputId": "13691b33-90ab-40a4-c312-bf2302a33ec4"
   },
   "outputs": [],
   "source": [
    "for i in range(len(gray_people_10cat)):\n",
    "  plot_TSNE(gray_people_10cat[i], features_sar,'responses', targets_material_8, colors_material_8, perplexity_level = 15)\n",
    "  print(\"TSNE plot for color observer with 8 categories\", i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2apoqsRrRVvw"
   },
   "source": [
    "# Image Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2dFKl1_MR1xj"
   },
   "outputs": [],
   "source": [
    "image_stat_color = imag_stat(color_attributes_rank)\n",
    "image_stat_color.to_csv('/content/drive/MyDrive/SAR Color data/image_stats_sept30.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "SAR-BC Paper code cleaned.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
