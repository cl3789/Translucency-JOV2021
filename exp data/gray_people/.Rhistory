.after="track_popularity")
music_popularity
boxplot(track_popularity~playlist_genre,
data=music_popularity,
main="Different boxplots for each month",
xlab="Month Number",
ylab="Degree Fahrenheit",
col="orange",
border="brown"
)
boxplot(track_popularity~playlist_genre,
data=music_popularity,
main="Boxplots for each Genre",
xlab="Genre",
ylab="Track Popularity Score",
col="green",
border="brown"
)
ggplot(music_popularity, aes(x=playlist_genre, y=track_popularity, fill=playlist_genre)) +
geom_boxplot(alpha=0.3) +
theme(legend.position="none") +
scale_fill_brewer(palette="Dark2")
ggplot(music_popularity, aes(x=playlist_genre, y=track_popularity, fill=playlist_genre)) +
geom_boxplot(alpha=0.3) +
theme(legend.position="none") +
scale_fill_brewer(palette="BuPu")
ggplot(music_popularity, aes(x=playlist_genre, y=track_popularity, fill=playlist_genre)) +
geom_boxplot(alpha=0.3) +
theme(legend.position="none") +
scale_fill_brewer(palette="Dark2")
ggplot(music_popularity, aes(x=playlist_genre, y=track_popularity, fill=playlist_genre)) +
geom_boxplot(alpha=0.3) +
theme(legend.position="none") +
scale_fill_brewer(palette="Dark2") +
ggtitle("Boxplot of Track Popularity for each Genre") +
xlab("Genres") +
ylab("Track Popularity")
music_popularity$playlist_genre <- as.factor(music_popularity$playlist_genre)
music_popularity$Is_Popular <- as.factor(music_popularity$Is_Popular)
music_popularity
music_popularity <- music_popularity[-c(2)]
music_popularity$playlist_genre <- as.factor(music_popularity$playlist_genre)
music_popularity$Is_Popular <- as.factor(music_popularity$Is_Popular)
music_popularity
pop_split <- initial_split(music_popularity, strata = Is_Popular)
train_popular <- training(pop_split)
test_popular <- testing(pop_split)
lr_spec <- logistic_reg() %>%
set_engine("glm") %>%
set_mode("classification")
## Create workflow
lr_wf <- workflow() %>%
add_model(lr_spec) %>%
add_formula(Is_Popular ~ .) ## Set Predictors and Response
pop_folds <- vfold_cv(data = train_popular, v = 3)
## Fit the model within each of the folds. And save the prediction result
pop_fold_result <- fit_resamples(object = lr_wf, resamples = pop_folds,
control = control_resamples(save_pred = TRUE))
collect_metrics(pop_fold_result)
lr_spec <- logistic_reg() %>%
set_engine("glm") %>%
set_mode("classification")
## Create workflow
lr_wf <- workflow() %>%
add_model(lr_spec) %>%
add_formula(Is_Popular ~ danceability + energy + loudness + speechiness + acousticness + instrumentalness + liveness + valence) ## Set Predictors and Response
pop_folds <- vfold_cv(data = train_popular, v = 3)
## Fit the model within each of the folds. And save the prediction result
pop_fold_result <- fit_resamples(object = lr_wf, resamples = pop_folds,
control = control_resamples(save_pred = TRUE))
collect_metrics(pop_fold_result)
lr_spec <- logistic_reg() %>%
set_engine("glm") %>%
set_mode("classification")
## Create workflow
lr_wf <- workflow() %>%
add_model(lr_spec) %>%
add_formula(Is_Popular ~ danceability + energy + loudness + speechiness + acousticness + instrumentalness + liveness + valence) ## Set Predictors and Response
pop_folds <- vfold_cv(data = train_popular, v = 5)
## Fit the model within each of the folds. And save the prediction result
pop_fold_result <- fit_resamples(object = lr_wf, resamples = pop_folds,
control = control_resamples(save_pred = TRUE))
collect_metrics(pop_fold_result)
lr_prediction <- predict(lr_wf, new_data = test_popular)
lr_fit <- lr_spec %>%
fit(Is_Popular ~ danceability + energy + loudness + speechiness + acousticness
+ instrumentalness + liveness + valence, data = train_popular  )
lr_prediction <- predict(lr_fit, new_data = test_popular)
bind_cols(
lr_prediction,
test_popular
) %>%
accuracy(truth = Is_Popular, estimate =.pred_class)
lr_spec <- logistic_reg() %>%
set_engine("glm") %>%
set_mode("classification")
## Create workflow
lr_wf <- workflow() %>%
add_model(lr_spec) %>%
add_formula(Is_Popular ~ danceability + energy + loudness + speechiness +
acousticness + instrumentalness + liveness + valence) ## Set Predictors and Response
pop_folds <- vfold_cv(data = train_popular, v = 5)
## Fit the model within each of the folds. And save the prediction result
pop_fold_result <- fit_resamples(object = lr_wf, resamples = pop_folds,
control = control_resamples(save_pred = TRUE))
collect_metrics(pop_fold_result)
lr_fit <- lr_spec %>%
fit(Is_Popular ~ danceability + energy + loudness + speechiness + acousticness
+ instrumentalness + liveness + valence, data = train_popular  )
lr_prediction <- predict(lr_fit, new_data = test_popular)
bind_cols(
lr_prediction,
test_popular
) %>%
accuracy(truth = Is_Popular, estimate =.pred_class)
bind_cols(
lr_prediction,
test_popular
) %>%
conf_mat(truth = Is_Popular, estimate=.pred_class)%>%
autoplot(type = "heatmap")
music_popularity
music_popularity <- all_music[-c(1:9,12,17)]
music_popularity
music_popularity <- all_music[-c(1:9,12,17)]
music_popularity
quantile(music_popularity$track_popularity)
music_popularity <- music_popularity %>%
add_column(Is_Popular =
if_else(.$track_popularity > 62, "Hit", "Flop"),
.after="track_popularity")
music_popularity <- music_popularity[-c(1:2)]
#music_popularity$playlist_genre <- as.factor(music_popularity$playlist_genre)
music_popularity$Is_Popular <- as.factor(music_popularity$Is_Popular)
music_popularity
pop_split <- initial_split(music_popularity, strata = Is_Popular)
train_popular <- training(pop_split)
test_popular <- testing(pop_split)
lr_spec <- logistic_reg() %>%
set_engine("glm") %>%
set_mode("classification")
## Create workflow
lr_wf <- workflow() %>%
add_model(lr_spec) %>%
add_formula(Is_Popular ~ danceability + energy + loudness + speechiness +
acousticness + instrumentalness + liveness + valence) ## Set Predictors and Response
pop_folds <- vfold_cv(data = train_popular, v = 5)
## Fit the model within each of the folds. And save the prediction result
pop_fold_result <- fit_resamples(object = lr_wf, resamples = pop_folds,
control = control_resamples(save_pred = TRUE))
collect_metrics(pop_fold_result)
lr_fit <- lr_spec %>%
fit(Is_Popular ~ danceability + energy + loudness + speechiness + acousticness
+ instrumentalness + liveness + valence, data = train_popular  )
lr_prediction <- predict(lr_fit, new_data = test_popular)
bind_cols(
lr_prediction,
test_popular
) %>%
accuracy(truth = Is_Popular, estimate =.pred_class)
bind_cols(
lr_prediction,
test_popular
) %>%
conf_mat(truth = Is_Popular, estimate=.pred_class)%>%
autoplot(type = "heatmap")
bind_cols(
lr_prediction,
test_popular
) %>%
accuracy(truth = Is_Popular, estimate =.pred_class)%>%
conf_mat(truth = Is_Popular, estimate=.pred_class)%>%
autoplot(type = "heatmap")
bind_cols(
lr_prediction,
test_popular
) %>%
conf_mat(truth = Is_Popular, estimate=.pred_class)%>%
autoplot(type = "heatmap")
knitr::opts_chunk$set(echo = TRUE)
dance_year <- pivot(all_music, mean, danceability, Year)
## Import necessary libraries
library(tidymodels)
library(lessR)
library(dplyr)
library(Rtsne)
library(nnet)
library(ggplot2)
library(rpart.plot)
library(vip)
library(xgboost)
library(kernlab)
library(cluster)
library(factoextra)
library(corrplot)
library(kknn)
barplot(prop.table(table(all_music$Year)),
xlab = "Year",
ylab = "Proportion",
main = "Distribution of Sound Track wrt. Year"
)
barplot(prop.table(table(all_music$playlist_genre)), col = rgb(0.2, 0.4, 0.5, 0.5),
xlab = "Genres",
ylab = "Proportion",
main = "Distribution of Sound Track wrt. Genres"
)
year_genre <- pivot(all_music, tabulate, c(Year, playlist_genre))
year_genre %>%
ggplot(mapping = aes(x = Year, y = n, group = playlist_genre, color = playlist_genre)) +
geom_line() + theme(axis.text.x = element_text(angle = 90,  size = 5)) +
ggtitle("Genres by Year") +
xlab("Year 1905 to 2020") + ylab("Number of Sound Track")
dance_year <- pivot(all_music, mean, danceability, Year)
dance_year %>%
ggplot(mapping = aes(x = Year, y = danceability)) +
geom_line() + theme(axis.text.x = element_text(angle = 90,  size = 5)) +
ggtitle("Mean of Dancebility by Year") +  xlim(1960,2020) +
xlab("Year 1960 to 2020") + ylab("Mean danceability score")
## Select necessary audio features
feature_names <- names(all_music[-c(1:12,15,17,23:24)])
feature_names
## Plot the correlation matrix
all_music %>%
select(feature_names) %>%
scale() %>%
cor() %>%
corrplot(type = "upper")
set.seed(1)
plot_cluster <- function(cluster_num) {
music_kmeans <- kmeans(music_selected_feature, cluster_num)
music_pca = prcomp(music_selected_feature, center = TRUE, scale. = TRUE)
music_pca$cluster <- music_kmeans$cluster
music_pca$cluster <- as.factor(music_pca$cluster)
pca_cluster <- data.frame('Cluster' = music_pca$cluster, music_pca$x[,1:2])
ggplot(data = pca_cluster) +
geom_point(aes(x = PC1, y = PC2, col = Cluster)) +
theme_minimal() + ggtitle("PCA visualization of K-means clustering")
}
plot_cluster(3)
music_selected_feature <- all_music[-c(1:12,15,17,23:24)]
music_selected_feature
set.seed(1)
plot_cluster <- function(cluster_num) {
music_kmeans <- kmeans(music_selected_feature, cluster_num)
music_pca = prcomp(music_selected_feature, center = TRUE, scale. = TRUE)
music_pca$cluster <- music_kmeans$cluster
music_pca$cluster <- as.factor(music_pca$cluster)
pca_cluster <- data.frame('Cluster' = music_pca$cluster, music_pca$x[,1:2])
ggplot(data = pca_cluster) +
geom_point(aes(x = PC1, y = PC2, col = Cluster)) +
theme_minimal() + ggtitle("PCA visualization of K-means clustering")
}
plot_cluster(3)
plot_cluster(4)
plot_cluster(5)
plot_cluster(6)
music_pca = prcomp(music_selected_feature, center = TRUE, scale. = TRUE)
music_pca$genre <- all_music$playlist_genre
music_pca$genre <- as.factor(music_pca$genre)
pca_cluster <- data.frame('Genre' = music_pca$genre, music_pca$x[,1:2])
ggplot(data = pca_cluster) +
geom_point(aes(x = PC1, y = PC2, col = Genre)) +
theme_minimal() + ggtitle("PCA visualization of 6 Genres")
tidy(music_pca, matrix = "loadings") %>%
arrange(PC)
tidy(music_pca, matrix = "eigenvalues") %>%
ggplot(aes(PC, percent)) +
geom_col()
loan_var=music_pca$sdev ^2
pve = loan_var/sum(loan_var)
pve
tidy(music_pca, matrix = "loadings") %>%
filter(PC == 1) %>%
ggplot(aes(abs(value), column)) +
geom_col()
tidy(music_pca, matrix = "loadings") %>%
filter(PC == 1) %>%
ggplot(aes(abs(value), column)) +
geom_col() + ggtitle("Contributions to the first principle component")
tidy(music_pca, matrix = "loadings") %>%
filter(PC == 1) %>%
ggplot(aes(abs(value), column)) +
geom_col() + ggtitle("Contributions to the 1st principle component")
tidy(music_pca, matrix = "loadings") %>%
filter(PC == 2) %>%
ggplot(aes(abs(value), column)) +
geom_col() + ggtitle("Contributions to the 2nd principle component")
tidy(music_pca, matrix = "eigenvalues") %>%
ggplot(aes(PC, percent)) +
geom_col() + ggtitle("PC loadings")
best_param <- select_by_one_std_err(tree_tune_res, "rmse")
best_param
bind_cols(
testing_pred_tree,
test_music
) %>%
conf_mat(truth = genre, estimate=.pred_class)%>%
autoplot(type = "heatmap")
bind_cols(
testing_pred_tree,
test_music %>% select(genre),
) %>%
accuracy(truth = genre, estimate = .pred_class)
bind_cols(
testing_pred_boost,
test_music
) %>%
conf_mat(truth = genre, estimate=.pred_class)%>%
autoplot(type = "heatmap")
testing_pred_boost = predict(final_fitted_boost, new_data = test_music)
View(testing_pred_tree)
bind_cols(
testing_pred_boost,
test_music
) %>%
conf_mat(truth = genre, estimate=.pred_class)%>%
autoplot(type = "heatmap")
## Set a tuned Random Forest spec: tuning number of decision trees, the number of features for each tree, and minimum number of data points in a node
boost_tune_spec <- boost_tree(
trees = tune(),
min_n = tune(),
tree_depth = tune(),
#learn_rate = tune()
) %>%
set_mode("classification") %>%
set_engine("xgboost") %>%
translate()
boost_tune_wf <- workflow() %>%
add_recipe(rec_spec) %>%
add_model(boost_tune_spec)
boost_tune_res <- tune_grid(
boost_tune_wf,
resamples = trees_folds,
grid = 5,
)
boost_tune_res
collect_metrics(boost_tune_res)
boost_best_param <- select_by_one_std_err(boost_tune_res, "rmse")
boost_best_param
final_wf_boost <- finalize_workflow(boost_tune_wf, boost_best_param)
final_fitted_boost <- final_wf_boost %>%
fit(train_music)
testing_pred_boost = predict(final_fitted_boost, new_data = test_music)
bind_cols(
testing_pred_boost,
test_music %>% select(genre),
) %>%
accuracy(truth = genre, estimate = .pred_class)
bind_cols(
testing_pred_boost,
test_music
) %>%
conf_mat(truth = genre, estimate=.pred_class)%>%
autoplot(type = "heatmap")
setwd("~/Dropbox/Mac/Documents/Research/analysis/gray_people")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
gray1 <- read.csv("Gray Person1.csv")
View(gray1)
gray1 <- read.csv("Gray Person1.csv")
gray1
gray1 <- read.csv("Gray Person1.csv")
gray1$label <- as.factor(gray1$label)
gray1
set.seed(1)
lr_spec <- logistic_reg() %>%
set_engine("glm") %>%
set_mode("classification")
install.packages("library(tidymodels)")
library(tidyverse)
library(tidymodel)
library(tidyverse)
library(kernlab)
install.packages("kernlab")
library(tidyverse)
library(kernlab)
set.seed(1)
lr_spec <- logistic_reg() %>%
set_engine("glm") %>%
set_mode("classification")
library(tidyverse)
library(tidymodels)
install.packages("tidymodels")
library(tidyverse)
library(tidymodels)
set.seed(1)
lr_spec <- logistic_reg() %>%
set_engine("glm") %>%
set_mode("classification")
## Create workflow
lr_wf <- workflow() %>%
add_model(lr_spec) %>%
add_formula(label ~ see_throughness + glossiness + glow + softness + density) ## Set Predictors and Response
folds <- vfold_cv(data = gray1, v = 3, strata = label)
## Fit the model within each of the folds. And save the prediction result
fold_result <- fit_resamples(object = lr_wf, resamples = folds,
control = control_resamples(save_pred = TRUE))
collect_metrics(fold_result)
lr_fit <- lr_spec %>%
fit(label ~ see_throughness + glossiness + glow + softness + density, data = gray1  )
## Calculate classification accuracy of LR model
lr_prediction <- predict(lr_fit, new_data = gray1)
bind_cols(
lr_prediction,
gray1
) %>%
accuracy(truth = label, estimate =.pred_class)
set.seed(1)
lr_spec <- logistic_reg() %>%
set_engine("glm") %>%
set_mode("classification")
## Create workflow
lr_wf <- workflow() %>%
add_model(lr_spec) %>%
add_formula(label ~ see_throughness + glossiness + glow + softness + density) ## Set Predictors and Response
folds <- vfold_cv(data = gray1, v = 3, strata = label)
## Fit the model within each of the folds. And save the prediction result
fold_result <- fit_resamples(object = lr_wf, resamples = folds,
control = control_resamples(save_pred = TRUE))
collect_metrics(fold_result)
lr_fit <- lr_spec %>%
fit(label ~ see_throughness + glossiness + glow + softness + density, data = gray1  )
## Calculate classification accuracy of LR model
lr_prediction <- predict(lr_fit, new_data = gray1)
bind_cols(
lr_prediction,
gray1
) %>%
#accuracy(truth = label, estimate =.pred_class)
conf_mat(truth = label, estimate=.pred_class)%>%
autoplot(type = "heatmap", title = "Classification Result of Logistic Regression")
gray1 <- read.csv("Gray Person2.csv")
gray1$label <- as.factor(gray1$label)
set.seed(1)
lr_spec <- logistic_reg() %>%
set_engine("glm") %>%
set_mode("classification")
## Create workflow
lr_wf <- workflow() %>%
add_model(lr_spec) %>%
add_formula(label ~ see_throughness + glossiness + glow + softness + density) ## Set Predictors and Response
folds <- vfold_cv(data = gray1, v = 3, strata = label)
## Fit the model within each of the folds. And save the prediction result
fold_result <- fit_resamples(object = lr_wf, resamples = folds,
control = control_resamples(save_pred = TRUE))
collect_metrics(fold_result)
lr_fit <- lr_spec %>%
fit(label ~ see_throughness + glossiness + glow + softness + density, data = gray1  )
## Calculate classification accuracy of LR model
lr_prediction <- predict(lr_fit, new_data = gray1)
bind_cols(
lr_prediction,
gray1
) %>%
#accuracy(truth = label, estimate =.pred_class)
conf_mat(truth = label, estimate=.pred_class)%>%
autoplot(type = "heatmap", title = "Classification Result of Logistic Regression")
gray1 %>% count(label, sort = TRUE)
gray1 <- read.csv("Gray Person2.csv")
gray1$label <- as.factor(gray1$label)
gray1 %>% count(label, sort = TRUE)
set.seed(1)
lr_spec <- logistic_reg() %>%
set_engine("glm") %>%
set_mode("classification")
## Create workflow
lr_wf <- workflow() %>%
add_model(lr_spec) %>%
add_formula(label ~ see_throughness + glossiness + glow + softness + density) ## Set Predictors and Response
folds <- vfold_cv(data = gray1, v = 3, strata = label)
## Fit the model within each of the folds. And save the prediction result
fold_result <- fit_resamples(object = lr_wf, resamples = folds,
control = control_resamples(save_pred = TRUE))
collect_metrics(fold_result)
lr_fit <- lr_spec %>%
fit(label ~ see_throughness + glossiness + glow + softness + density, data = gray1  )
## Calculate classification accuracy of LR model
lr_prediction <- predict(lr_fit, new_data = gray1)
bind_cols(
lr_prediction,
gray1
) %>%
#accuracy(truth = label, estimate =.pred_class)
conf_mat(truth = label, estimate=.pred_class)%>%
autoplot(type = "heatmap", title = "Classification Result of Logistic Regression")
gray1 <- read.csv("Gray Person2.csv")
gray1$label <- as.factor(gray1$label)
gray1 %>% count(label, sort = TRUE)
set.seed(1)
lr_spec <- logistic_reg() %>%
set_engine("glm") %>%
set_mode("classification")
## Create workflow
lr_wf <- workflow() %>%
add_model(lr_spec) %>%
add_formula(label ~ see_throughness + glossiness + glow + softness + density) ## Set Predictors and Response
folds <- vfold_cv(data = gray1, v = 3, strata = label)
## Fit the model within each of the folds. And save the prediction result
fold_result <- fit_resamples(object = lr_wf, resamples = folds,
control = control_resamples(save_pred = TRUE))
collect_predictions(fold_result)
lr_fit <- lr_spec %>%
fit(label ~ see_throughness + glossiness + glow + softness + density, data = gray1  )
## Calculate classification accuracy of LR model
lr_prediction <- predict(lr_fit, new_data = gray1)
bind_cols(
lr_prediction,
gray1
) %>%
#accuracy(truth = label, estimate =.pred_class)
conf_mat(truth = label, estimate=.pred_class)%>%
autoplot(type = "heatmap", title = "Classification Result of Logistic Regression")
